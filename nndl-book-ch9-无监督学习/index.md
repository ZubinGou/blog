# ã€Šç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ã€‹ç¬¬9ç«  - æ— ç›‘ç£å­¦ä¹ 

ch9 æ— ç›‘ç£å­¦ä¹ 

## 9.1 æ— ç›‘ç£ç‰¹å¾å­¦ä¹ 
æ— ç›‘ç£å­¦ä¹ é—®é¢˜åˆ†ç±»ï¼š
1. æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ï¼ˆUnsupervised Feature Learningï¼‰
	- é™ç»´ã€å¯è§†åŒ–ã€ç›‘ç£å­¦ä¹ å‰çš„é¢„å¤„ç†
2. æ¦‚ç‡å¯†åº¦ä¼°è®¡ï¼ˆProbabilistic Density Estimationï¼‰
3. èšç±»ï¼ˆClusteringï¼‰
	- K-Meansã€è°±èšç±»

ç›‘ç£å­¦ä¹ ã€æ— ç›‘ç£å­¦ä¹ ä¸‰è¦ç´ ï¼š
1. æ¨¡å‹
2. å­¦ä¹ å‡†åˆ™
	- æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆå¯†åº¦ä¼°è®¡å¸¸ç”¨ï¼‰ã€æœ€å°é‡æ„é”™è¯¯ï¼ˆæ— ç›‘ç£ç‰¹å¾å­¦ä¹ å¸¸ç”¨ï¼‰
3. ä¼˜åŒ–ç®—æ³•

### 9.1.1 ä¸»æˆåˆ†åˆ†æ

ä¸»æˆåˆ†åˆ†æï¼ˆPrincipal Component Analysisï¼ŒPCAï¼‰ï¼šæ•°æ®é™ç»´ï¼Œä½¿è½¬æ¢åçš„ç©ºé—´ä¸­æ•°æ®æ–¹å·®æœ€å¤§ã€‚

æ ·æœ¬æŠ•å½±æ–¹å·®ï¼š

$$
\begin{aligned}
\sigma(\boldsymbol{X} ; \boldsymbol{w}) &=\frac{1}{N} \sum\_{n=1}^{N}\left(\boldsymbol{w}^{\top} \boldsymbol{x}^{(n)}-\boldsymbol{w}^{\top} \overline{\boldsymbol{x} }\right)^{2} \\\\
&=\frac{1}{N}\left(\boldsymbol{w}^{\top} \boldsymbol{X}-\boldsymbol{w}^{\top} \overline{\boldsymbol{X} }\right)\left(\boldsymbol{w}^{\top} \boldsymbol{X}-\boldsymbol{w}^{\top} \overline{\boldsymbol{X} }\right)^{\top} \\\\
&=\boldsymbol{w}^{\top} \boldsymbol{\Sigma} \boldsymbol{w}
\end{aligned}
$$

å…¶ä¸­ï¼š

$$
\boldsymbol{\Sigma}=\frac{1}{N}(\boldsymbol{X}-\overline{\boldsymbol{X} })(\boldsymbol{X}-\overline{\boldsymbol{X} })^{\top}
$$

å³åŸæ ·æœ¬çš„åæ–¹å·®çŸ©é˜µã€‚

æ‹‰æ ¼æœ—æ—¥æ–¹æ³•è½¬åŒ–ä¸ºæ— çº¦æŸä¼˜åŒ–ï¼š

$$
\max \_{\boldsymbol{w} } \boldsymbol{w}^{\top} \boldsymbol{\Sigma} \boldsymbol{w}+\lambda\left(1-\boldsymbol{w}^{\top} \boldsymbol{w}\right)
$$

æ±‚å¯¼ä»¤å¯¼æ•°ä¸º0ï¼š

$$
\boldsymbol{\Sigma} \boldsymbol{w}=\lambda \boldsymbol{w}
$$

ğ’˜ æ˜¯åæ–¹å·®çŸ©é˜µ ğšº çš„ç‰¹å¾å‘é‡ï¼Œğœ† ä¸ºç‰¹å¾å€¼ï¼åŒæ—¶
$$
\sigma(\boldsymbol{X} ; \boldsymbol{w})=\boldsymbol{w}^{\top} \boldsymbol{\Sigma} \boldsymbol{w}=\boldsymbol{w}^{\top} \lambda \boldsymbol{w}=\lambda
$$

å› æ­¤ï¼ŒPCA å¯ä»¥è½¬æ¢ä¸ºçŸ©é˜µç‰¹å¾å€¼åˆ†è§£ï¼ŒæŠ•å½±å‘é‡ ğ’˜ ä¸ºçŸ©é˜µ ğšº çš„æœ€å¤§ç‰¹å¾å€¼å¯¹åº”çš„ç‰¹å¾å‘é‡ã€‚å–å‰ $D'$ ä¸ªç‰¹å¾å‘é‡ï¼š

$$
\boldsymbol{\Sigma} \boldsymbol{W}=\boldsymbol{W} \operatorname{diag}(\lambda)
$$

PCA å‡å°‘äº†æ•°æ®ç›¸å…³æ€§ï¼Œä½†ä¸èƒ½ä¿è¯æŠ•å½±åæ•°æ®ç±»åˆ«å¯åˆ†æ€§æ›´å¥½ã€‚æé«˜å¯åˆ†ç±»æ€§çš„æ–¹æ³•ä¸€èˆ¬ä¸ºç›‘ç£æ–¹æ³•ï¼Œå¦‚çº¿æ€§åˆ¤åˆ«åˆ†æï¼ˆLinear Discriminant Analysisï¼ŒLDAï¼‰

PCA ä¸€ä¸ªæ˜æ˜¾çš„ç¼ºç‚¹æ˜¯å¤±å»äº†ç‰¹å¾çš„å¯è§£é‡Šæ€§ã€‚

### 9.1.2 ç¨€ç–ç¼–ç 
ç¨€ç–ç¼–ç ï¼ˆSparse Codingï¼‰

å¯å‘ï¼šå“ºä¹³åŠ¨ç‰©è§†è§‰ç»†èƒæ„Ÿå—é‡ï¼Œæ¯ä¸ªç¥ç»å…ƒä»…å¯¹å…¶æ„Ÿå—é‡çš„ç‰¹å®šåˆºæ¿€åšå‡ºå“åº”ï¼Œå¤–ç•Œåˆºæ¿€å­åœ¨è§†è§‰ç¥ç»ç³»ç»Ÿçš„è¡¨ç¤ºå…·æœ‰ç¨€ç–æ€§ï¼Œç¬¦åˆç”Ÿç‰©ä½åŠŸè€—ç‰¹æ€§ã€‚

çº¿æ€§ç¼–ç ï¼šå°†è¾“å…¥çš„æ ·æœ¬è¡¨ç¤ºä¸ºä¸€ç»„åŸºå‘é‡çš„çº¿æ€§ç»„åˆï¼Œåœ¨ P ç»´ç©ºé—´ä¸­è¡¨ç¤º D ç»´ç©ºé—´çš„æ ·æœ¬ xï¼š

$$
\begin{aligned}
\boldsymbol{x} &=\sum\_{m=1}^{M} z\_{m} \boldsymbol{a}\_{m} \\\\
&=\boldsymbol{A z},
\end{aligned}
$$

åŸºå‘é‡ A ä¹Ÿç§°ä¸ºå­—å…¸

ç¼–ç çš„å…³é”®ï¼šæ‰¾åˆ°ä¸€ç»„å®Œå¤‡åŸºå‘é‡ï¼Œå¦‚é€šè¿‡PCAã€‚PCAå¾—åˆ°çš„ç¼–ç é€šå¸¸æ˜¯ç¨ å¯†å‘é‡ï¼Œæ²¡æœ‰ç¨€ç–æ€§ã€‚

> å®Œå¤‡ï¼šåŸºå‘é‡æ•°ç­‰äºå…¶æ”¯æ’‘ç»´åº¦ï¼ˆç»„æˆæ»¡ç§©æ–¹é˜µï¼‰
> è¿‡å®Œå¤‡ï¼šåŸºå‘é‡æ•°å¤§äºå…¶æ”¯æ’‘çš„ç»´åº¦ã€‚

ä¸ºäº†å¾—åˆ°ç¨€ç–ç¼–ç ï¼Œå¯ä»¥æ‰¾ä¸€ç»„â€œè¿‡å®Œå¤‡â€çš„åŸºå‘é‡ï¼ŒåŠ ä¸Šç¨€ç–æ€§é™åˆ¶ï¼Œå¾—åˆ°â€œå”¯ä¸€â€ç¨€ç–ç¼–ç ã€‚

å¯¹ä¸€ç»„è¾“å…¥ x çš„ç¨€ç–ç¼–ç ç›®æ ‡å‡½æ•°ï¼š
$$
\mathcal{L}(\boldsymbol{A}, \boldsymbol{Z})=\sum\_{n=1}^{N}\left(\left\|\boldsymbol{x}^{(n)}-A \boldsymbol{z}^{(n)}\right\|^{2}+\eta \rho\left(\boldsymbol{z}^{(n)}\right)\right),
$$

ğœŒ(â‹…) æ˜¯ä¸€ä¸ªç¨€ç–æ€§è¡¡é‡å‡½æ•°ï¼Œğœ‚ æ˜¯ä¸€ä¸ªè¶…å‚æ•°ï¼Œç”¨æ¥æ§åˆ¶ç¨€ç–æ€§çš„å¼ºåº¦

ç¨€ç–æ€§å®šä¹‰ï¼šå‘é‡éé›¶å…ƒç´ çš„æ¯”ä¾‹ã€‚å¤§å¤šæ•°å…ƒç´ æ¥è¿‘é›¶çš„å‘é‡ä¹Ÿæˆä¸ºç¨€ç–å‘é‡ã€‚

**è¡¡é‡ç¨€ç–æ€§**

$\ell\_{0}$ èŒƒæ•°ï¼š

$$
\rho(\boldsymbol{z})=\sum\_{m=1}^{M} \mathbf{I}\left(\left|z\_{m}\right|>0\right)
$$

ä¸æ»¡è¶³è¿ç»­å¯å¯¼ï¼Œå¾ˆéš¾ä¼˜åŒ–ï¼Œæ‰€ä»¥ç¨€ç–æ€§è¡¡é‡å‡½æ•°å¸¸ä½¿ç”¨ $\ell\_{1}$ èŒƒæ•°ï¼š

$$
\rho(\boldsymbol{z})=\sum\_{m=1}^{M}\left|z\_{m}\right|
$$

æˆ–å¯¹æ•°å‡½æ•°ï¼š

$$
\rho(\boldsymbol{z})=\sum\_{m=1}^{M} \log \left(1+z\_{m}^{2}\right)
$$

æˆ–æŒ‡æ•°å‡½æ•°ï¼š

$$
\rho(z)=\sum\_{m=1}^{M}-\exp \left(-z\_{m}^{2}\right)
$$

ç¨€ç–è¡¨ç¤ºçš„æœ¬è´¨ï¼šç”¨å°½å¯èƒ½å°‘çš„èµ„æºè¡¨ç¤ºå°½å¯èƒ½å¤šçš„çŸ¥è¯†ï¼Œäººè„‘çš®è´¨å±‚å­¦ä¹ è¾“å…¥è¡¨å¾é‡‡ç”¨äº†è¿™ä¸€æ–¹æ³•ï¼Œå¯¹ç†Ÿç»ƒçš„ä¸œè¥¿ä¼šè°ƒç”¨æ›´å°‘çš„è„‘åŒºåŸŸã€‚

**è®­ç»ƒæ–¹æ³•**
è®­ç»ƒç›®æ ‡ï¼šåŸºå‘é‡Aã€æ¯ä¸ªè¾“å…¥çš„è¡¨ç¤º

ä¼˜åŒ–æ–¹æ³•ï¼šäº¤æ›¿ä¼˜åŒ–
1. å›ºå®šåŸºå‘é‡ï¼Œä¼˜åŒ–ç¼–ç ï¼š

$$
\min \_{z^{(n)} }\left\|\boldsymbol{x}^{(n)}-\boldsymbol{A} \boldsymbol{z}^{(n)}\right\|^{2}+\eta \rho\left(\boldsymbol{z}^{(n)}\right), \forall n \in[1, N]
$$

2. å›ºå®šç¼–ç ï¼Œä¼˜åŒ–åŸºå‘é‡ï¼š

$$
\min \_{\boldsymbol{A} } \sum\_{n=1}^{N}\left(\left\|\boldsymbol{x}^{(n)}-\boldsymbol{A} \boldsymbol{z}^{(n)}\right\|^{2}\right)+\lambda \frac{1}{2}\|\boldsymbol{A}\|^{2}
$$

**ç¨€ç–ç¼–ç ä¼˜ç‚¹ï¼ˆç›¸æ¯”ç¨ å¯†å‘é‡çš„åˆ†å¸ƒå¼è¡¨ç¤ºï¼‰**
1. è®¡ç®—é‡å°
2. å¯è§£é‡Šæ€§å¼ºï¼šç¼–ç å¯¹åº”å°‘æ•°ç‰¹å¾
3. ç‰¹å¾é€‰æ‹©ï¼šè‡ªåŠ¨é€‰æ‹©å’Œè¾“å…¥ç›¸å…³çš„å°‘æ•°ç‰¹å¾ï¼Œé™ä½å™ªå£°ï¼Œå‡å°‘è¿‡æ‹Ÿåˆã€‚


### 9.1.3 è‡ªç¼–ç å™¨
è‡ªç¼–ç å™¨ï¼ˆAuto-Encoderï¼ŒAEï¼‰ï¼šé€šè¿‡æ— ç›‘ç£æ–¹æ³•å­¦ä¹ ä¸€ç»„æ•°æ®çš„æœ‰æ•ˆç¼–ç 

æ€è·¯ï¼šå°† x é€šè¿‡ç¼–ç å™¨è½¬æ¢ä¸ºä¸­é—´å˜é‡ yï¼Œå†å°† y é€šè¿‡è§£ç å™¨è½¬æ¢ä¸ºè¾“å‡º $\bar{x}$ï¼Œç›®æ ‡æ˜¯ä½¿å¾—è¾“å‡ºå’Œè¾“å…¥æ— é™æ¥è¿‘ã€‚

ä½œç”¨ï¼šä½¿ç”¨å…¶ä¸­çš„ç¼–ç å™¨è¿›è¡Œç‰¹å¾é™ç»´ï¼Œä½œä¸º ML æ¨¡å‹çš„è¾“å…¥ã€‚

ä¼˜åŒ–ç›®æ ‡ï¼šæœ€å°é‡æ„é”™è¯¯ï¼ˆReconstrcution Errorï¼‰ï¼š

$$
\begin{aligned}
\mathcal{L} &=\sum\_{n=1}^{N}\left\|\boldsymbol{x}^{(n)}-g\left(f\left(\boldsymbol{x}^{(n)}\right)\right)\right\|^{2} \\\\
&=\sum\_{n=1}^{N}\left\|\boldsymbol{x}^{(n)}-f \circ g\left(\boldsymbol{x}^{(n)}\right)\right\|^{2} .
\end{aligned}
$$

- ç‰¹å¾ç©ºé—´ç»´åº¦ M ä¸€èˆ¬å°äºåŸå§‹ç©ºé—´ç»´åº¦ï¼ŒAE ç›¸å½“äºæ˜¯é™ç»´/ç‰¹å¾æŠ½å–ã€‚
- å½“ $M \geq D$ æ—¶ï¼Œå­˜åœ¨è§£ä½¿å¾— $f \circ g$ ä¸ºå•ä½å‡½æ•°ï¼Œä½¿å¾—æŸå¤±ä¸º0ï¼Œè§£å°±æ²¡æœ‰å¤ªå¤šæ„ä¹‰ã€‚
- å½“åŠ ä¸Šé™åˆ¶ï¼Œå¦‚ç¼–ç ç¨€ç–æ€§ã€å–å€¼èŒƒå›´ã€få’Œgçš„å½¢å¼ç­‰ï¼Œå¯ä»¥å¾—åˆ°æœ‰æ„ä¹‰çš„è§£

> å¦‚è®©ç¼–ç åªèƒ½å» K ä¸ªä¸åŒçš„å€¼ï¼Œåˆ™å˜ä¸ºäº† K èšç±»é—®é¢˜ã€‚

![387ff345a4e6635d6ca899745edba0cd.png](../../../_resources/f7159ea0351e4c169a448a92cc1e8652.png)

ç¼–ç å™¨ï¼š

$$
\boldsymbol{z}=f\left(\boldsymbol{W}^{(1)} \boldsymbol{x}+\boldsymbol{b}^{(1)}\right)
$$

è§£ç å™¨ï¼š

$$
\boldsymbol{x}^{\prime}=f\left(\boldsymbol{W}^{(2)} \boldsymbol{z}+\boldsymbol{b}^{(2)}\right)
$$

æ†ç»‘æƒé‡ï¼ˆTied Weightï¼‰ï¼šä»¤ $\boldsymbol{W}^{(2)}=\boldsymbol{W}^{(1)^{\top} }$ ï¼Œå‚æ•°æ›´å°‘ï¼Œæ›´å®¹æ˜“å­¦ä¹ ï¼ŒåŒæ—¶æœ‰ä¸€å®šæ­£åˆ™åŒ–ä½œç”¨ã€‚

é‡æ„é”™è¯¯ï¼š

$$
\mathcal{L}=\sum\_{n=1}^{N} \| \boldsymbol{x}^{(n)}-\boldsymbol{x}^{\prime(n)}\|^{2}+\lambda\| \boldsymbol{W} \|\_{F}^{2}
$$


### 9.1.4 ç¨€ç–è‡ªç¼–ç å™¨
ç¨€ç–è‡ªç¼–ç å™¨ï¼ˆSparse Auto-Encoderï¼‰ï¼šè®©ç‰¹å¾ç»´åº¦ M å¤§äºè¾“å…¥ç»´åº¦ Dï¼Œå¹¶ä½¿ç‰¹å¾å°½é‡ç¨€ç–çš„è‡ªç¼–ç å™¨ã€‚

ç›®æ ‡å‡½æ•°ï¼š

$$
\mathcal{L}=\sum\_{n=1}^{N} \| \boldsymbol{x}^{(n)}-\boldsymbol{x}^{\prime(n)}\|^{2}+\eta \rho(\boldsymbol{Z})+\lambda\| \boldsymbol{W} \|^{2}
$$

ğœŒ(ğ’) ä¸ºç¨€ç–æ€§åº¦é‡å‡½æ•°ï¼Œå¯ä»¥ç”¨ç¨€ç–ç¼–ç çš„ç¨€ç–è¡¡é‡å‡½æ•°ï¼Œä¹Ÿå¯ä»¥å®šä¹‰ä¸ºä¸€ç»„è®­ç»ƒæ ·æœ¬ä¸­æ¯ä¸ªç¥ç»å…ƒæ¿€æ´»çš„æ¦‚ç‡ï¼Œç”¨å¹³å‡æ´»æ€§å€¼è¿‘ä¼¼ï¼š

$$
\hat{\rho}\_{j}=\frac{1}{N} \sum\_{n=1}^{N} z\_{j}^{(n)}
$$

æˆ‘ä»¬å¸Œæœ›ç¨€ç–åº¦æ¥è¿‘å®ç°ç»™å®šçš„å€¼ $\rho^*$ï¼Œå¦‚0.05ï¼Œç”¨ KL è·ç¦»è¡¡é‡ï¼š
$$
\mathrm{KL}\left(\rho^{*} \| \hat{\rho}\_{j}\right)=\rho^{*} \log \frac{\rho^{*} }{\hat{\rho}\_{j} }+\left(1-\rho^{*}\right) \log \frac{1-\rho^{*} }{1-\hat{\rho}\_{j} }
$$

ç¨€ç–æ€§åº¦é‡å‡½æ•°å®šä¹‰ä¸ºï¼š
$$
\rho(\boldsymbol{Z})=\sum\_{j=1}^{p} \mathrm{KL}\left(\rho^{*} \| \hat{\rho}\_{j}\right)
$$

### 9.1.5 å †å è‡ªç¼–ç å™¨
å †å è‡ªç¼–ç å™¨ï¼ˆStacked Auto-Encoderï¼ŒSAEï¼‰ï¼šä½¿ç”¨é€å±‚å †å çš„æ–¹å¼è®­ç»ƒæ·±å±‚çš„è‡ªç¼–ç å™¨ï¼Œå¯ä»¥é‡‡ç”¨é€å±‚è®­ç»ƒï¼ˆLayer-Wise Trainingï¼‰æ¥å­¦ä¹ å‚æ•°ã€‚

### 9.1.6 é™å™ªè‡ªç¼–ç å™¨
é™å™ªè‡ªç¼–ç å™¨ï¼ˆDenoising Auto-Encoderï¼‰ï¼šé€šè¿‡å¼•å…¥å™ªå£°æ¥å¢åŠ ç¼–ç é²æ£’æ€§çš„è‡ªç¼–ç å™¨ã€‚

![cb284fd8da4888a86a1779974f3c4999.png](../../../_resources/373033d6f5ff487f856b739063c54882.png)


## 9.2 æ¦‚ç‡å¯†åº¦ä¼°è®¡

æ¦‚ç‡å¯†åº¦ä¼°è®¡ï¼ˆProbabilistic Density Estimationï¼‰ï¼šç®€ç§°å¯†åº¦ä¼°è®¡ï¼Œå³åŸºäºæ ·æœ¬ä¼°è®¡éšæœºå˜é‡çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚

### 9.2.1 å‚æ•°å¯†åº¦ä¼°è®¡
å‚æ•°å¯†åº¦ä¼°è®¡ï¼ˆParametric Density Estimationï¼‰ï¼šæ ¹æ®å…ˆéªŒçŸ¥è¯†å‡è®¾éšæœºå˜é‡æœä»æŸç§åˆ†å¸ƒï¼Œç„¶åç”¨è®­ç»ƒæ ·æœ¬ä¼°è®¡åˆ†å¸ƒçš„å‚æ•°ã€‚

å¯¹æ ·æœ¬ D çš„å¯¹æ•°ä¼¼ç„¶å‡½æ•°ï¼š
$$
\log p(\mathcal{D} ; \theta)=\sum\_{n=1}^{N} \log p\left(\boldsymbol{x}^{(n)} ; \theta\right)
$$

å¯ä»¥ä½¿ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡ï¼ˆMLEï¼‰æ¥å¯»æ‰¾å‚æ•°ï¼Œå‚æ•°ä¼°è®¡é—®é¢˜è½¬å˜ä¸ºæœ€ä¼˜åŒ–é—®é¢˜ï¼š
$$
\theta^{M L}=\underset{\theta}{\arg \max } \sum\_{n=1}^{N} \log p\left(\boldsymbol{x}^{(n)} ; \theta\right) .
$$

**æ­£æ€åˆ†å¸ƒ**

![c0a11ab6135c5b571e3009894635f6f5.png](../../../_resources/ffa1e97aa8204808b9cceb74cca652f2.png)

**å¤šé¡¹åˆ†å¸ƒ**

![62536cdcd2d549dfd9b192d7698543ae.png](../../../_resources/81f5231f3b2643d6a7cfecef6fb5efc0.png)

æ±‚å¯¼æ•°ä¸º0å¾—ï¼š

$$
\mu\_{k}^{M L}=\frac{m\_{k} }{N}, \quad 1 \leq k \leq K
$$

å‚æ•°å¯†åº¦ä¼°è®¡çš„é—®é¢˜ï¼š
1. æ¨¡å‹é€‰æ‹©ï¼šå®é™…åˆ†å¸ƒå¾€å¾€å¤æ‚
2. ä¸å¯è§‚æµ‹ï¼šä¸€äº›å…³é”®å˜é‡æ— æ³•è§‚æµ‹ï¼Œå¾ˆéš¾å‡†ç¡®ä¼°è®¡æ•°æ®çœŸå®åˆ†å¸ƒ
3. ç»´åº¦ç¾éš¾ï¼šé«˜ç»´æ•°æ®å‚æ•°ä¼°è®¡å›°éš¾ï¼Œéœ€è¦å¤§é‡æ ·æœ¬é¿å…è¿‡æ‹Ÿåˆã€‚

### 9.2.2 éå‚æ•°å¯†åº¦ä¼°è®¡
éå‚æ•°å¯†åº¦ä¼°è®¡ï¼ˆNonparametric Density Estimationï¼‰ï¼šä¸å‡è®¾æ•°æ®æœä»æŸç§åˆ†å¸ƒï¼Œé€šè¿‡æ ·æœ¬ç©ºé—´åˆ’åˆ†ä¸ºä¸åŒçš„åŒºåŸŸå¹¶ä¼°è®¡æ¯ä¸ªåŒºåŸŸæ¦‚ç‡æ¥è¿‘ä¼¼æ¦‚ç‡å¯†åº¦å‡½æ•°ã€‚

é«˜ç»´ç©ºé—´ä¸­éšæœºå‘é‡ xï¼Œå‡è®¾å…¶æœä»æœªçŸ¥åˆ†å¸ƒ p(x)ï¼Œåˆ™ x è½å…¥å°åŒºåŸŸ R çš„æ¦‚ç‡ä¸ºï¼š

$$
P=\int\_{\mathcal{R} } p(\boldsymbol{x}) d \boldsymbol{x} .
$$

N ä¸ªæ ·æœ¬ä¸­è½å…¥ R çš„æ•°é‡ K æœä»äºŒé¡¹åˆ†å¸ƒï¼š

$$
P\_{K}=(\begin{array}{l}
N \\\\
K
\end{array}) P^{K}(1-P)^{1-K}
$$

N å¾ˆå¤§æ—¶ï¼Œå¯ä»¥è¿‘ä¼¼è®¤ä¸ºï¼š

$$
P \approx \frac{K}{N}
$$

å‡è®¾ R è¶³å¤Ÿå°ï¼Œå†…éƒ¨æ¦‚ç‡å‡åŒ€ï¼š

$$
P \approx p(\boldsymbol{x}) V
$$

ç»¼ä¸Šï¼š

$$
p(\boldsymbol{x}) \approx \frac{K}{N V}
$$

éå‚æ•°å¯†åº¦ä¼°è®¡å¸¸ç”¨æ–¹æ³•ï¼š
1. å›ºå®šåŒºåŸŸ Vï¼Œç»Ÿè®¡è½å…¥ä¸åŒåŒºåŸŸçš„æ•°é‡
	- ç›´æ–¹å›¾æ–¹æ³•
	- æ ¸æ–¹æ³•
2. æ”¹å˜åŒºåŸŸå¤§å°ï¼Œä½¿å¾—è½å…¥æ¯ä¸ªåŒºåŸŸçš„æ ·æœ¬æ•°é‡ä¸º Kï¼šKé‚»è¿‘æ³•

**ç›´æ–¹å›¾æ–¹æ³•ï¼ˆHistogram Methodï¼‰**
ç›´è§‚å¯è§†åŒ–ä½ç»´æ•°æ®åˆ†å¸ƒï¼Œå¾ˆéš¾æ‰©å±•åˆ°é«˜ç»´å˜é‡ï¼ˆç»´åº¦ç¾éš¾ï¼‰


**æ ¸å¯†åº¦ä¼°è®¡ï¼ˆKernel Density Estimationï¼‰**
ä¹Ÿå« Parzen çª—æ–¹æ³•

å®šä¹‰è¶…ç«‹æ–¹ä½“æ ¸å‡½æ•°ï¼š
$$
\phi\left(\frac{\boldsymbol{z}-\boldsymbol{x} }{H}\right)= \begin{cases}1 & \text { if }\left|z\_{i}-x\_{i}\right|<\frac{H}{2}, 1 \leq i \leq D \\\\ 0 & \text { else }\end{cases}
$$

æ±‚å’Œå¾—åˆ°è½å…¥ R åŒºåŸŸçš„æ ·æœ¬æ•°é‡ï¼š

$$
K=\sum\_{n=1}^{N} \phi\left(\frac{\boldsymbol{x}^{(n)}-\boldsymbol{x} }{H}\right)
$$

x ç‚¹æ¦‚ç‡å¯†åº¦ä¼°è®¡ï¼š

$$
p(\boldsymbol{x})=\frac{K}{N H^{D} }=\frac{1}{N H^{D} } \sum\_{n=1}^{N} \phi\left(\frac{\boldsymbol{x}^{(n)}-\boldsymbol{x} }{H}\right)
$$

ä¹Ÿå¯ä»¥é‡‡ç”¨æ›´åŠ å¹³æ»‘çš„é«˜æ–¯æ ¸å‡½æ•°ï¼š

$$
\phi\left(\frac{z-x}{H}\right)=\frac{1}{(2 \pi)^{1 / 2} H} \exp \left(-\frac{\|z-x\|^{2} }{2 H^{2} }\right)
$$

åˆ™ x ç‚¹æ¦‚ç‡å¯†åº¦ä¼°è®¡ï¼š

$$
p(\boldsymbol{x})=\frac{1}{N} \sum\_{n=1}^{N} \frac{1}{(2 \pi)^{1 / 2} H} \exp \left(-\frac{\|\boldsymbol{z}-\boldsymbol{x}\|^{2} }{2 H^{2} }\right)
$$

**K è¿‘é‚»æ–¹æ³•ï¼ˆK-Nearest Neighbor Methodï¼‰**
ä¼°è®¡ x ç‚¹å¯†åº¦ï¼š
1. æ‰¾åˆ°ä»¥ x ä¸ºä¸­å¿ƒçš„çƒä½“ï¼Œä½¿å¾—è½å…¥çƒä½“çš„æ ·æœ¬æ•°é‡ä¸º K
2. åˆ©ç”¨ä¸‹å¼è®¡ç®—å¯†åº¦ï¼š

$$
p(\boldsymbol{x}) \approx \frac{K}{N V}
$$

## 9.3 æ€»ç»“å’Œæ·±å…¥é˜…è¯»
æ¦‚ç‡å¯†åº¦ä¼°è®¡ä¸åæ–‡å…³è”ï¼š
- ch11ï¼šé€šè¿‡æ¦‚ç‡å›¾æ¨¡å‹ä»‹ç»æ›´ä¸€èˆ¬çš„å‚æ•°å¯†åº¦ä¼°è®¡æ–¹æ³•ï¼ŒåŒ…æ‹¬å«éšå˜é‡çš„å‚æ•°ä¼°è®¡æ–¹æ³•
- ch12ï¼šä¸¤ç§æ¯”è¾ƒå¤æ‚çš„ç”Ÿæˆæ¨¡å‹ï¼šç»å°”å…¹æ›¼æœºã€æ·±åº¦ä¿¡å¿µç½‘ç»œ
- ch13ï¼šä¸¤ç§æ·±åº¦ç”Ÿæˆæ¨¡å‹ï¼šå˜åˆ†è‡ªç¼–ç å™¨ã€å¯¹æŠ—ç”Ÿæˆç½‘ç»œ
- ch15ï¼šåºåˆ—ç”Ÿæˆæ¨¡å‹

> ç”Ÿæˆæ¨¡å‹ï¼šæ ¹æ®å‚æ•°ä¼°è®¡å‡ºçš„æ¨¡å‹æ¥ç”Ÿæˆæ•°æ®ã€‚

æ— ç›‘ç£å­¦ä¹ æ²¡æœ‰ç›‘ç£å­¦ä¹ æˆåŠŸçš„åŸå› ï¼šç¼ºå°‘æœ‰æ•ˆçš„å®¢è§‚è¯„ä»·æ–¹æ³•ï¼Œæ— ç›‘ç£æ–¹æ³•å¥½åéœ€è¦ä»£å…¥ä¸‹æ¸¸ä»»åŠ¡ä¸­éªŒè¯ã€‚

## ä¹ é¢˜é€‰åš
#### ä¹ é¢˜ 9-1 åˆ†æä¸»æˆåˆ†åˆ†æä¸ºä»€ä¹ˆå…·æœ‰æ•°æ®é™å™ªèƒ½åŠ›ï¼Ÿ
PCAçš„æ ¸å¿ƒæ€æƒ³æ˜¯ï¼šå°†æ•°æ®é›†æ˜ å°„åˆ°ç”¨ä¸€ç»„ç‰¹å¾å‘é‡ï¼ˆåŸºï¼‰æ¥è¡¨ç¤ºï¼Œæ•°æ®é›†åœ¨æŸä¸ªåŸºä¸Šçš„æŠ•å½±å³æ˜¯ç‰¹å¾å€¼ã€‚å™ªå£°ä¸ä¸»è¦ç‰¹å¾ä¸€èˆ¬ä¸ç›¸å…³ï¼Œæ‰€ä»¥è¾ƒå°çš„ç‰¹å¾å€¼å¾€å¾€å¯¹åº”ç€å™ªå£°çš„æ–¹å·®ï¼Œå»æ‰è¾ƒå°çš„ç‰¹å¾å¯ä»¥å‡å°å™ªå£°ã€‚

#### ä¹ é¢˜ 9-3 å¯¹äºä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ï¼Œè¯•ä¸¾ä¾‹åˆ†æä»€ä¹ˆæ ·çš„æ•°æ®åˆ†å¸ƒä¼šä½¿å¾—ä¸»æˆåˆ†åˆ†æå¾—åˆ°çš„ç‰¹å¾åè€Œä¼šä½¿å¾—åˆ†ç±»æ€§èƒ½ä¸‹é™ï¼
ä¸æ»¡è¶³æ–¹å·®è¶Šå¤§ï¼Œä¿¡æ¯é‡è¶Šå¤šçš„å‡è®¾æ—¶ï¼Œå¦‚ä¸‹å›¾ï¼š

![864f3722f01240db2d3552b44c453ad3.png](../../../_resources/0ca43124885f4d1a9f8c84aefa6ee1a7.png)

PCA ä¼šæŒ‰ç…§ y è½´é™ç»´ï¼Œä½¿å¾—æ•°æ®ä¸¤ç±»æ•°æ®æ··åœ¨ä¸€èµ·è€Œä¸å¯åˆ†ï¼ˆè¿™é‡Œå¯ä»¥ä½¿ç”¨æœ‰ç›‘ç£çš„ LDA é™ç»´ï¼‰ã€‚

åŒæ ·ï¼Œå½“å™ªå£°è¿‡å¤§æ—¶ã€æ•°æ®ç»´åº¦æœ¬èº«è¾ƒå°æ—¶ï¼Œä¹Ÿä¸é€‚åˆç”¨PCAã€‚


#### ä¹ é¢˜ 9-5 ä¸¾ä¾‹è¯´æ˜ï¼ŒK è¿‘é‚»æ–¹æ³•ä¼°è®¡çš„å¯†åº¦å‡½æ•°ä¸æ˜¯ä¸¥æ ¼çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå…¶åœ¨æ•´ä¸ªç©ºé—´ä¸Šçš„ç§¯åˆ†ä¸ç­‰äº 1ï¼

> exercise 2.61: Show that the K-nearest-neighbor density model defines an improper distribution whose integral over all space is divergent.
> -- Bishop's pattern recognition and machine learning

è¯æ˜æ€è·¯ï¼šæ¦‚ç‡å¯†åº¦å‡½æ•°åœ¨ $(-\infty, \infty)$ ä¸Šæ±‚ç§¯åˆ†ä¸æ”¶æ•›åˆ°1ï¼Œè€Œæ˜¯ $\infty$


å‡è®¾ä¸€ç»´æ¡ä»¶ä¸‹ $K=1$ çš„ KNN å¯†åº¦ä¼°è®¡ï¼Œæœ‰ä¸€ä¸ªç‚¹ $x=0$ï¼Œåˆ™ $x$ å¤„å¯†åº¦ä¼°è®¡ä¸ºï¼š

$$
p(x)=\frac{K}{N V}=\frac{1}{|x|}
$$

å…¶ä¸­ ğ‘‰ ä¸ºåŒºåŸŸ â„› çš„ä½“ç§¯ã€‚

å½“ $N=1$ æ—¶æ»¡è¶³ï¼š
$$
\int\_{-\infty}^{\infty} p(x) \mathrm{d} x=\infty
$$

å½“ $N \gt 1$ æ—¶ï¼Œå‡è®¾æœ‰ä¸€ç³»åˆ—ç‚¹ï¼š

$$
X\_{1} \leq X\_{2} \leq \ldots \leq X\_{N}
$$

å¯¹ $x\leq X_1$ çš„éƒ¨åˆ†ï¼š

$$
p(x)=\frac{K}{N\left(X\_{k}-x\right)}, \quad x \leq X\_{1}
$$

æˆ‘ä»¬åªè®¡ç®—è¿™éƒ¨åˆ†çš„ç§¯åˆ†ï¼š

$$
\int\_{-\infty}^{X\_{1} } \frac{K}{N\left(X\_{k}-x\right)} \mathrm{d} x=\left[\frac{K}{N} \ln \left|X\_{k}-x\right|\right]\_{-\infty}^{X\_{1} }=\infty
$$

ç”±äºå¯†åº¦ä¸ºæ­£ï¼Œæ‰€ä»¥åœ¨ $(-\infty, \infty)$ ä¸Šçš„ç§¯åˆ†ä¹Ÿå‘æ•£ï¼Œä»è€Œè¯´æ˜äº† KNN å¯†åº¦ä¼°è®¡å¹¶ä¸ä¸¥æ ¼ã€‚
